{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waihongthong/RaspberryPi-object-measurement/blob/main/DrowningYolo8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJo7ORiGyiC4"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics opencv-python torch seaborn torchvision numpy pandas seaborn tqdm matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ue_XDLkn_aEc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwABA7WL_c_3"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive (for Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0W8BjAXV2Tr"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content/drive/MyDrive/Final Dataset'\n",
        "train_path = os.path.join(dataset_path, 'train')\n",
        "val_path = os.path.join(dataset_path, 'valid')\n",
        "test_path = os.path.join(dataset_path, 'test')\n",
        "video_path = os.path.join(dataset_path, 'videos')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UB_Mhixu_9cX"
      },
      "outputs": [],
      "source": [
        "# Check if dataset exists\n",
        "print(f\"Train path exists: {os.path.exists(train_path)}\")\n",
        "print(f\"Val path exists: {os.path.exists(val_path)}\")\n",
        "print(f\"Test path exists: {os.path.exists(test_path)}\")\n",
        "print(f\"Video path exists: {os.path.exists(test_path)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSq1BnAbBLTh"
      },
      "outputs": [],
      "source": [
        "print(\"Processing videos for training data...\")\n",
        "extracted_frames_path = os.path.join(dataset_path, 'extracted_frames')\n",
        "os.makedirs(extracted_frames_path, exist_ok=True)\n",
        "\n",
        "if os.path.exists(video_path) and os.path.isdir(video_path):\n",
        "    video_files = [f for f in os.listdir(video_path) if f.endswith(('.mp4', '.avi', '.mov'))]\n",
        "\n",
        "    # Process each video file\n",
        "    for video_file in video_files:\n",
        "        video_filepath = os.path.join(video_path, video_file)\n",
        "        print(f\"Processing video: {video_file}\")\n",
        "\n",
        "        # Determine if video contains drowning (based on filename or your own logic)\n",
        "        is_drowning = 'drowning' in video_file.lower()\n",
        "        label_class = 1 if is_drowning else 0  # 1 for drowning, 0 for normal\n",
        "\n",
        "        # Extract frames\n",
        "        cap = cv2.VideoCapture(video_filepath)\n",
        "        frame_count = 0\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "        # Extract 1 frame per second\n",
        "        frame_interval = int(fps)\n",
        "\n",
        "        video_name = os.path.splitext(video_file)[0]\n",
        "\n",
        "        # Create directory for this video's frames\n",
        "        video_frames_dir = os.path.join(extracted_frames_path, video_name)\n",
        "        os.makedirs(video_frames_dir, exist_ok=True)\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Process every nth frame (based on frame_interval)\n",
        "            if frame_count % frame_interval == 0:\n",
        "                frame_filename = f\"{video_name}_frame_{frame_count:05d}.jpg\"\n",
        "                frame_path = os.path.join(video_frames_dir, frame_filename)\n",
        "                cv2.imwrite(frame_path, frame)\n",
        "\n",
        "                # Create label file (YOLO format)\n",
        "                # Format: <class> <x_center> <y_center> <width> <height>\n",
        "                # We're assuming the full frame may contain a drowning/normal person\n",
        "                h, w, _ = frame.shape\n",
        "                label_filename = f\"{video_name}_frame_{frame_count:05d}.txt\"\n",
        "                label_path = os.path.join(video_frames_dir, label_filename)\n",
        "\n",
        "                # Create a basic label file - this is just an example\n",
        "                # In real use, you would need precise annotations\n",
        "                with open(label_path, 'w') as f:\n",
        "                    # Center of the image with 80% width and height\n",
        "                    f.write(f\"{label_class} 0.5 0.5 0.8 0.8\\n\")\n",
        "\n",
        "                print(f\"  Extracted frame {frame_count//frame_interval} ({frame_count}/{total_frames})\")\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "        cap.release()\n",
        "        print(f\"  Extracted {frame_count//frame_interval} frames from {video_file}\")\n",
        "\n",
        "    # Distribute the extracted frames to train/val/test directories\n",
        "    print(\"\\nDistributing extracted frames to train/val/test sets...\")\n",
        "    video_dirs = [d for d in os.listdir(extracted_frames_path) if os.path.isdir(os.path.join(extracted_frames_path, d))]\n",
        "\n",
        "    for video_dir in video_dirs:\n",
        "        frames_dir = os.path.join(extracted_frames_path, video_dir)\n",
        "        frame_files = [f for f in os.listdir(frames_dir) if f.endswith('.jpg')]\n",
        "\n",
        "        # Split frames into train (70%), val (15%), test (15%)\n",
        "        num_frames = len(frame_files)\n",
        "        train_split = int(0.7 * num_frames)\n",
        "        val_split = int(0.15 * num_frames)\n",
        "\n",
        "        # Shuffle frame files for better distribution\n",
        "        np.random.shuffle(frame_files)\n",
        "\n",
        "        for i, frame_file in enumerate(frame_files):\n",
        "            frame_path = os.path.join(frames_dir, frame_file)\n",
        "            label_file = frame_file.replace('.jpg', '.txt')\n",
        "            label_path = os.path.join(frames_dir, label_file)\n",
        "\n",
        "            # Determine destination directory\n",
        "            if i < train_split:\n",
        "                dest_dir = train_path\n",
        "            elif i < train_split + val_split:\n",
        "                dest_dir = val_path\n",
        "            else:\n",
        "                dest_dir = test_path\n",
        "\n",
        "            # Copy frame and label files\n",
        "            shutil.copy(frame_path, os.path.join(dest_dir, frame_file))\n",
        "            if os.path.exists(label_path):\n",
        "                shutil.copy(label_path, os.path.join(dest_dir, label_file))\n",
        "else:\n",
        "    print(\"Video directory not found. Skipping video processing.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lh-F_CuzRxYX"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained YOLOv8 model\n",
        "model = YOLO('yolov8n.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXaQ_fhlTnuN"
      },
      "outputs": [],
      "source": [
        "# Create a YAML file for dataset configuration\n",
        "yaml_content = \"path: \" + dataset_path + \"\\n\"\n",
        "yaml_content += \"train: \" + train_path + \"\\n\"\n",
        "yaml_content += \"val: \" + val_path + \"\\n\"\n",
        "yaml_content += \"test: \" + test_path + \"\\n\\n\"\n",
        "yaml_content += \"# Classes\\n\"\n",
        "yaml_content += \"names:\\n\"\n",
        "yaml_content += \"  0: person\\n\"\n",
        "yaml_content += \"  1: drowning_person\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhUAsDcaP03e"
      },
      "outputs": [],
      "source": [
        "# Write YAML file\n",
        "yaml_path = os.path.join(dataset_path, 'drowning_dataset.yaml')\n",
        "with open(yaml_path, 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(\"Dataset configuration YAML file created.\")\n",
        "\n",
        "# Train the model\n",
        "print(\"Starting model training...\")\n",
        "model.train(\n",
        "    data=yaml_path,\n",
        "    epochs=10,\n",
        "    imgsz=412,\n",
        "    batch=64,\n",
        "    workers=8,\n",
        "    patience=5,\n",
        "    save=True,\n",
        "    project='drowning_detection',\n",
        "    name='yolov8_drowning',\n",
        "    amp=True,\n",
        "    cache=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGdktXdUEkiO"
      },
      "outputs": [],
      "source": [
        "# Load the best trained model\n",
        "trained_model = YOLO(os.path.join('drowning_detection', 'yolov8_drowning', 'weights', 'best.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWzFBg9fMDrn"
      },
      "outputs": [],
      "source": [
        "print(\"\\nEvaluating model on test videos...\")\n",
        "test_video_path = os.path.join(dataset_path, 'test_videos')  # Path to test videos\n",
        "\n",
        "if os.path.exists(test_video_path) and os.path.isdir(test_video_path):\n",
        "    # Create directory for results\n",
        "    results_dir = \"video_results\"\n",
        "    os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "    video_files = [f for f in os.listdir(test_video_path) if f.endswith(('.mp4', '.avi', '.mov'))]\n",
        "\n",
        "    # Process each test video\n",
        "    for video_file in video_files:\n",
        "        print(f\"Processing test video: {video_file}\")\n",
        "        video_path = os.path.join(test_video_path, video_file)\n",
        "\n",
        "        # Run tracking on video\n",
        "        results = trained_model.track(source=video_path, save=True, tracker=\"botsort.yaml\",\n",
        "                                     project=results_dir, name=os.path.splitext(video_file)[0])\n",
        "\n",
        "        print(f\"Processed {video_file} - results saved to {results_dir}/{os.path.splitext(video_file)[0]}\")\n",
        "else:\n",
        "    print(\"Test video directory not found. Skipping video evaluation.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2TD4pyEP6q-"
      },
      "outputs": [],
      "source": [
        "# Initialize variables for metrics calculation\n",
        "y_true = []\n",
        "y_pred = []\n",
        "id_tracker = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UdvXx_9E7mr"
      },
      "outputs": [],
      "source": [
        "print(\"Evaluating model on test dataset...\")\n",
        "test_files = [os.path.join(test_path, f) for f in os.listdir(test_path) if f.endswith(('.jpg', '.jpeg', '.png', ))]\n",
        "\n",
        "for file in tqdm(test_files):\n",
        "    # Extract ground truth from filename or corresponding label file\n",
        "    # This depends on your dataset structure, modify as needed\n",
        "    label_file = file.replace('.jpg', '.txt').replace('.jpeg', '.txt').replace('.png', '.txt')\n",
        "\n",
        "    if os.path.exists(label_file):\n",
        "        with open(label_file, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            gt_classes = [int(line.split()[0]) for line in lines]\n",
        "            # If any class is 1 (drowning_person), mark as drowning\n",
        "            is_drowning_gt = 1 in gt_classes\n",
        "            y_true.append(int(is_drowning_gt))\n",
        "    else:\n",
        "        # No label file, assume no drowning\n",
        "        y_true.append(0)\n",
        "\n",
        "    # Run detection on the image\n",
        "    results = trained_model.track(source=file, persist=True, tracker=\"botsort.yaml\")\n",
        "\n",
        "    # Process the results\n",
        "    is_drowning_pred = False\n",
        "    unique_ids = set()\n",
        "\n",
        "    for r in results:\n",
        "        if r.boxes.id is not None:  # Check if IDs are available\n",
        "            boxes = r.boxes.xyxy.cpu().numpy()\n",
        "            classes = r.boxes.cls.cpu().numpy()\n",
        "            ids = r.boxes.id.int().cpu().numpy()\n",
        "\n",
        "            for box, cls, id in zip(boxes, classes, ids):\n",
        "                # Track unique IDs across frames\n",
        "                unique_ids.add(id)\n",
        "\n",
        "                # Update tracker\n",
        "                if id not in id_tracker:\n",
        "                    id_tracker[id] = {\"frames\": 1, \"drowning_frames\": 1 if cls == 1 else 0}\n",
        "                else:\n",
        "                    id_tracker[id][\"frames\"] += 1\n",
        "                    if cls == 1:\n",
        "                        id_tracker[id][\"drowning_frames\"] += 1\n",
        "\n",
        "                # If class is 1 (drowning_person), mark as drowning\n",
        "                if cls == 1:\n",
        "                    is_drowning_pred = True\n",
        "\n",
        "    y_pred.append(int(is_drowning_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDmuZpZrF8R7"
      },
      "outputs": [],
      "source": [
        "# Calculate metrics\n",
        "print(\"\\nPerformance Metrics:\")\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DFqAmRpGBce"
      },
      "outputs": [],
      "source": [
        "# Detailed classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "target_names = ['Normal', 'Drowning']\n",
        "report = classification_report(y_true, y_pred, target_names=target_names)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnGjXVu-Gejn"
      },
      "outputs": [],
      "source": [
        "print(\"\\nUnique ID Statistics:\")\n",
        "for id, stats in id_tracker.items():\n",
        "    drowning_percentage = (stats[\"drowning_frames\"] / stats[\"frames\"]) * 100\n",
        "    status = \"POTENTIAL DROWNING\" if drowning_percentage > 50 else \"NORMAL\"\n",
        "    print(f\"ID {id:02d}: {status} ({drowning_percentage:.1f}% drowning frames)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKeQ-x6aTFaA"
      },
      "outputs": [],
      "source": [
        "# Visualize results with a confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ReppRI7TH2y"
      },
      "outputs": [],
      "source": [
        "# Save some example detections from test set\n",
        "os.makedirs('detection_results', exist_ok=True)\n",
        "sample_test_files = test_files[:5]  # Take first 5 test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMMDPoG7TLAy"
      },
      "outputs": [],
      "source": [
        "print(\"\\nGenerating sample detection visualizations...\")\n",
        "for i, file in enumerate(sample_test_files):\n",
        "    results = trained_model.track(source=file, persist=True, tracker=\"botsort.yaml\")\n",
        "\n",
        "    for r in results:\n",
        "        im_array = r.plot(line_width=2, font_size=1)  # Plot with detections and tracking IDs\n",
        "        img = cv2.cvtColor(im_array, cv2.COLOR_BGR2RGB)\n",
        "        output_path = f\"detection_results/sample_{i+1}.jpg\"\n",
        "        cv2.imwrite(output_path, img)\n",
        "        print(f\"Saved detection result to {output_path}\")\n",
        "\n",
        "print(\"\\nDrowning detection evaluation complete!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1LoohCQwq90jshxJV-jIb-5wOMpZjpj4k",
      "authorship_tag": "ABX9TyPHPld5f9H6DUtp3e09wjhw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}